import streamlit as st
st.set_page_config(page_title="TuringContent", page_icon="ğŸ ")
def intro():
    import streamlit as st
    from PIL import Image
    image = Image.open('Untitled.png')

    col1, col2 = st.columns([1,5], gap="small")
    with col1:
        st.image(image, width=100)
    with col2:
        st.write("# íŠœë§ ì½˜í…ì¸ íŒ€ ë¸”ë¡œê·¸")

    st.markdown("""
    íŠœë§ ì½˜í…ì¸ íŒ€ ë¸”ë¡œê·¸ì…ë‹ˆë‹¤.\\
    ì•ìœ¼ë¡œ ìˆ˜í•™, êµìœ¡, ì½˜í…ì¸  ë°ì´í„°ì™€ ê´€ë ¨ëœ ë‚´ìš©ì„ ì¶”ê°€í•  ì˜ˆì •ì…ë‹ˆë‹¤.\\
    ë§ì€ ê´€ì‹¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
    """)



#
#
#     st.markdown(
#         """
#         ### 0ï¸âƒ£ ì‹œì‘
#
#  **ê°€ì… ì‹œ ì…ë ¥í•œ ë°ì´í„°ê°€ DBì— ì—†ëŠ” ì‚¬ìš©ìì˜ ë°ì´í„°**ë¥¼ íŒŒì•…í•˜ê¸° ìœ„í•´
# * ì„¤ì •í•œ ê¸°ê°„ ë‚´ ê°€ì…í•œ ì‚¬ìš©ìë“¤ì´ ì‹¤í–‰í•œ ê°€ì¥ ì²« ì´ë²¤íŠ¸ ì´í›„ ì•Œ ìˆ˜ ìˆëŠ” ì •ë³´ë¡œ ì—†ëŠ” ë°ì´í„°ì…‹ êµ¬ì¶•
#
# í•´ë‹¹ DBê°€ athenaì— ìŠ¤ëƒ…ìƒ· í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆì–´
# * [Athena docs](https://docs.aws.amazon.com/athena/latest/ug/extracting-data-from-JSON.html)
# * [Presto docs](https://prestodb.io/docs/current/index.html)
# ë¥¼ ì°¸ê³ í–ˆë‹¤.
#
# Athenaì™€ Prestoì˜ ì°¨ì´ê°€ ê¶ê¸ˆí•´ ì°¾ì•„ë³´ë‹ˆ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•œë‹¤.[(stackshare ë§í¬)](https://stackshare.io/stackups/amazon-athena-vs-presto)
# * Athena : Query S3 Using SQL
# * Presto : Distributed SQL Query Engine for Big Data
#
#
# ---
# ### 1ï¸âƒ£ ì „ê°œ
# 1. ì„¤ì •í•œ ê¸°ê°„ ë‚´ ê°€ì…í•œ ê³ ë“±í•™ìƒ ì‚¬ìš©ì ì¤‘ì—ì„œ ì ì–´ë„ í•œ ë¬¸ì œë¥¼ í‘¼ ì‚¬ìš©ìì˜ ìˆ˜ë¥¼ ì¡°íšŒ
# 	* ê°€ì… ì‹œê°ì´ UTC ê¸°ì¤€ì´ë¼ KSTë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤.
#       * evnet_timeì´ 2022-08-24 08:00:00.000000+00ê³¼ ê°™ì€ timezoneí˜•ì‹ìœ¼ë¡œ ë˜ì–´ìˆì–´ KSTë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ date_parse í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.
#       * ë§Œì•½ date_parse í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œë„ í•  ìˆ˜ ìˆë‹¤.""")
#     st.code('''--Athena
# select
#     date_trunc('year', from_iso8601_timestamp(concat(substring(event_time, 1,10), 'T',SUBSTR(event_time, 12, 8)))) as year,
#     date_trunc('month', from_iso8601_timestamp(concat(substring(event_time, 1,10), 'T',SUBSTR(event_time, 12, 8)))) as month
# from eventtable''', language='sql')
#     st.markdown("""	* Postgresqlì—ì„œëŠ” '2022-08-24'ë¡œ í•˜ë©´ dateë¡œ ì¸ì‹í•˜ëŠ”ë° Athenaì—ì„œëŠ” cast í•¨ìˆ˜ë¥¼ í†µí•œ ë³€í™˜ì´ í•„ìš”í•˜ë‹¤.
# 	  * ë‚˜ëŠ” timestampë¡œ ë³€í™˜í•˜ì—¬ ì‚¬ìš©í–ˆë‹¤.
#     * ìœ„ì˜ ë‘ ê°€ì§€ë¥¼ í•©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì€ ëŠë‚Œìœ¼ë¡œ ì‘ì„±í•˜ì˜€ë‹¤.""")
#     st.code('''-- Athena
# -- UTC -> KST ë³€í™˜
# select
#   date_add('HOUR', 9, date_parse(substring(event_time, 1, 19), '%Y-%m-%d %H:%i:%s'))
# from eventtable
# where date_add('HOUR', 9, date_parse(substring(event_time, 1, 19), '%Y-%m-%d %H:%i:%s'))  between cast('ì‹œì‘ì¼ì‹œ ë° ì‹œì‘ì‹œê°' as timestamp) and cast('ì¢…ë£Œì¼ì‹œ ë° ì¢…ë£Œì‹œê°' as timestamp)
#         ''', language='sql')
#     st.markdown("""* ê´€ë ¨ ë‚´ìš©ì´ ìˆëŠ” ë¬¸ì„œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
#         * [Athena - date_parse](https://aws.amazon.com/ko/premiumsupport/knowledge-center/query-table-athena-timestamp-empty/)
#         * [Athena - date_add](https://docs.aws.amazon.com/ko_kr/redshift/latest/dg/r_DATEADD_function.html)
# 2. ì‚¬ìš©ìë³„ë¡œ ê°€ì¥ ì²« ì´ë²¤íŠ¸ë¥¼ í–ˆì„ ë•Œë¥¼ ì°¾ê¸°
# 	* ì„œë¸Œì¿¼ë¦¬ë¥¼ ì´ìš©í•˜ì—¬ user_idë¡œ group byí•˜ì—¬ min(event_time)ì„ êµ¬í•˜ê³ , where ì ˆì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ í…Œì´ë¸”ì— ìˆëŠ” ì´ë²¤íŠ¸ì˜ user_id, event_timeê³¼ ê°™ì€ ê²ƒë§Œ ë‚¨ê²¼ë‹¤.
# 3. ì°¾ì€ ê°€ì¥ ì²« ì´ë²¤íŠ¸ì— ëŒ€í•˜ì—¬ ì‚¬ìš©ìë³„ ë°ì´í„° ë³µêµ¬ ë° ë°ì´í„°ì…‹ êµ¬ì¶•
# 	* ë°ì´í„°ë¥¼ ë³µêµ¬í•˜ê¸° ìœ„í•´ ì—†ëŠ” ë°ì´í„° ê°’ì„ ìœ ì¶”í•  ìˆ˜ ìˆëŠ” JSON í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ìŠ¬ë¼ì´ì‹±í•˜ì˜€ë‹¤.
#       * ë°ì´í„°ë³„ë¡œ ë¦¬ìŠ¤íŠ¸ì˜ ê°œìˆ˜ê°€ ì¼ì •í•˜ì§€ ì•Šì•„ ì •ë§ í˜ë“¤ì—ˆë‹¤.
#       * ê´€ë ¨ ë‚´ìš©ì´ ìˆëŠ” ë¬¸ì„œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.
#         * [Presto - JSON Functions and Operators](https://prestodb.io/docs/current/functions/json.html)
#     * ì´í›„ ìŠ¬ë¼ì´ì‹±í•œ ë°ì´í„°ë¥¼ Excelì— ì˜®ê²¨ì™€ if í•¨ìˆ˜ë¥¼ ì—´ì‹¬íˆ ì‘ì„±í•˜ì—¬ ìš”ì²­ë°›ì€ ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì˜€ë‹¤.
#
# ---
# ### 2ï¸âƒ£ íšŒê³ 
# 1. ìœ„ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì¿¼ë¦¬ë¥¼ ì§œê³  ëŒë ¸ë”ë‹ˆ ì¡°íšŒí•˜ëŠ”ë° ìµœì†Œ 1ë¶„ì •ë„ ê±¸ë ¸ê³ , BEíŒ€ì›ì—ê²Œ ë“¤ì€ ë°”ë¡œëŠ” ì¿¼ë¦¬ í•œ ë²ˆ ëŒë¦¬ëŠ”ë° ë©”ëª¨ë¦¬ë¥¼ 9.7GBë‚˜ ì¡ì•„ë¨¹ëŠ”ë‹¤ê³  í•œë‹¤.
# 	* ì“¸ë°ì—†ì´ ë©”ëª¨ë¦¬ë¥¼ ì¡ì•„ë¨¹ì§€ ì•Šë„ë¡ joinì´ ìµœì†Œí™”ë˜ë„ë¡ í™•ì¸ì´ í•„ìš”í•˜ë‹¤.
#     * Athenaì˜ íŠ¹ì„±ì„ ì´ìš©í•œ ì¿¼ë¦¬ì¸ì§€ í™•ì¸ ë° ìµœì í™”ê°€ í•„ìš”í•˜ë‹¤.
#       * _ë‚ ì§œ(date) ë³„ë¡œ íŒŒí‹°ì…”ë‹ ë˜ì–´ìˆì–´ date ê¸°ì¤€ìœ¼ë¡œ where ë˜ëŠ” group by ë¬¸ì€ ë¹ ë¥´ê²Œ ìˆ˜í–‰ë¨_
# 2. JSON í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ììœ ë¡­ê²Œ í•¸ë“¤ë§í•˜ê³  ì‹¶ì€ë°, ê·¸ë ‡ì§€ ëª»í•˜ì—¬ ê°™ì€ ì¿¼ë¦¬ë¥¼ ìˆ˜ì‹­ë²ˆ ëŒë ¸ë‹¤.
# 	* JSON í˜•ì‹ì— ëŒ€í•œ ê³µë¶€ê°€ í•„ìš”í•˜ë‹¤.
#       * filtering, sortingí•˜ëŠ” ë°©ë²•ë„ ëª¨ë¥´ë‹ˆ ì •ë§ í˜ë“¤ì—ˆë‹¤.
#     * SQLë¡œ JSONì„ í•¸ë“¤ë§í•˜ê±°ë‚˜ csvíŒŒì¼ë¡œ ê°€ì ¸ì™€ pandasë¥¼ ì´ìš©í•˜ì—¬ í•¸ë“¤ë§í•  ìˆ˜ ìˆë„ë¡ í•´ì•¼ê² ë‹¤.
#       * ê·¸ëŸ°ë° ì•„ì§ pandasë¡œ JSONì„ í•¸ë“¤ë§í•˜ëŠ” ë°©ë²•ì„ ì •í™•íˆ ì•Œì§€ ëª»í•œë‹¤. ì´ ë˜í•œ ê³µë¶€ê°€ í•„ìš”í•˜ë‹¤.
# 3. ì¿¼ë¦¬ ê²°ê³¼ë¥¼ excelë¡œ ê°€ì ¸ì™€ í•¨ìˆ˜ë¥¼ í†µí•´ ìµœì¢… ë°ì´í„°ì…‹ì„ êµ¬ì¶•í•˜ì˜€ëŠ”ë°, ì´ í•¨ìˆ˜ì—°ì‚° ë˜í•œ ì¿¼ë¦¬ë¥¼ í†µí•´ í•  ìˆ˜ ìˆìœ¼ë©´ ë”ìš± íš¨ìœ¨ì ì¼ ê²ƒ ê°™ë‹¤.)
#
#
#     """
#     )

def Info():
    import streamlit as st
    # import pandas as pd
    # import pydeck as pdk
    from PIL import Image
    image = Image.open('Untitled.png')


    col1, col2 = st.columns([1, 5], gap="small")
    with col1:
        st.image(image, width=100)
    with col2:
        st.write("# íŠœë§ ì½˜í…ì¸ íŒ€ ë¸”ë¡œê·¸")


    tab1, tab2, tab3 = st.tabs(["Info", "Vision", "Contact"])

    with tab1:
        st.header("A cat")
        st.image("https://static.streamlit.io/examples/cat.jpg", width=200)

    with tab2:
        st.header("A dog")
        st.image("https://static.streamlit.io/examples/dog.jpg", width=200)

    with tab3:
        st.header("An owl")
        st.image("https://static.streamlit.io/examples/owl.jpg", width=200)
#
#     from urllib.error import URLError
#
#     st.markdown(f"# {list(page_names_to_funcs.keys())[2]}")
#     st.write(
#         """
#         This demo shows how to use
# [`st.pydeck_chart`](https://docs.streamlit.io/library/api-reference/charts/st.pydeck_chart)
# to display geospatial data.
# """
#     )
#
#     @st.cache
#     def from_data_file(filename):
#         url = (
#             "http://raw.githubusercontent.com/streamlit/"
#             "example-data/master/hello/v1/%s" % filename
#         )
#         return pd.read_json(url)
#
#     try:
#         ALL_LAYERS = {
#             "Bike Rentals": pdk.Layer(
#                 "HexagonLayer",
#                 data=from_data_file("bike_rental_stats.json"),
#                 get_position=["lon", "lat"],
#                 radius=200,
#                 elevation_scale=4,
#                 elevation_range=[0, 1000],
#                 extruded=True,
#             ),
#             "Bart Stop Exits": pdk.Layer(
#                 "ScatterplotLayer",
#                 data=from_data_file("bart_stop_stats.json"),
#                 get_position=["lon", "lat"],
#                 get_color=[200, 30, 0, 160],
#                 get_radius="[exits]",
#                 radius_scale=0.05,
#             ),
#             "Bart Stop Names": pdk.Layer(
#                 "TextLayer",
#                 data=from_data_file("bart_stop_stats.json"),
#                 get_position=["lon", "lat"],
#                 get_text="name",
#                 get_color=[0, 0, 0, 200],
#                 get_size=15,
#                 get_alignment_baseline="'bottom'",
#             ),
#             "Outbound Flow": pdk.Layer(
#                 "ArcLayer",
#                 data=from_data_file("bart_path_stats.json"),
#                 get_source_position=["lon", "lat"],
#                 get_target_position=["lon2", "lat2"],
#                 get_source_color=[200, 30, 0, 160],
#                 get_target_color=[200, 30, 0, 160],
#                 auto_highlight=True,
#                 width_scale=0.0001,
#                 get_width="outbound",
#                 width_min_pixels=3,
#                 width_max_pixels=30,
#             ),
#         }
#         st.sidebar.markdown("### Map Layers")
#         selected_layers = [
#             layer
#             for layer_name, layer in ALL_LAYERS.items()
#             if st.sidebar.checkbox(layer_name, True)
#         ]
#         if selected_layers:
#             st.pydeck_chart(
#                 pdk.Deck(
#                     map_style="mapbox://styles/mapbox/light-v9",
#                     initial_view_state={
#                         "latitude": 37.76,
#                         "longitude": -122.4,
#                         "zoom": 11,
#                         "pitch": 50,
#                     },
#                     layers=selected_layers,
#                 )
#             )
#         else:
#             st.error("Please choose at least one layer above.")
#     except URLError as e:
#         st.error(
#             """
#             **This demo requires internet access.**
#
#             Connection error: %s
#         """
#             % e.reason
#         )

def plotting_demo():
    import streamlit as st
    import time
    import numpy as np

    st.markdown(f'# {list(page_names_to_funcs.keys())[1]}')
    st.write(
        """
        This demo illustrates a combination of plotting and animation with
Streamlit. We're generating a bunch of random numbers in a loop for around
5 seconds. Enjoy!
"""
    )

    progress_bar = st.sidebar.progress(0)
    status_text = st.sidebar.empty()
    last_rows = np.random.randn(1, 1)
    chart = st.line_chart(last_rows)

    for i in range(1, 101):
        new_rows = last_rows[-1, :] + np.random.randn(5, 1).cumsum(axis=0)
        status_text.text("%i%% Complete" % i)
        chart.add_rows(new_rows)
        progress_bar.progress(i)
        last_rows = new_rows
        time.sleep(0.05)

    progress_bar.empty()

    # Streamlit widgets automatically run the script from top to bottom. Since
    # this button is not connected to any other logic, it just causes a plain
    # rerun.
    st.button("Re-run")


def data_frame_demo():
    import streamlit as st
    import pandas as pd
    import altair as alt

    from urllib.error import URLError

    st.markdown(f"# {list(page_names_to_funcs.keys())[3]}")
    st.write(
        """
        This demo shows how to use `st.write` to visualize Pandas DataFrames.

(Data courtesy of the [UN Data Explorer](http://data.un.org/Explorer.aspx).)
"""
    )

    @st.cache
    def get_UN_data():
        AWS_BUCKET_URL = "http://streamlit-demo-data.s3-us-west-2.amazonaws.com"
        df = pd.read_csv(AWS_BUCKET_URL + "/agri.csv.gz")
        return df.set_index("Region")

    try:
        df = get_UN_data()
        countries = st.multiselect(
            "Choose countries", list(df.index), ["China", "United States of America"]
        )
        if not countries:
            st.error("Please select at least one country.")
        else:
            data = df.loc[countries]
            data /= 1000000.0
            st.write("### Gross Agricultural Production ($B)", data.sort_index())

            data = data.T.reset_index()
            data = pd.melt(data, id_vars=["index"]).rename(
                columns={"index": "year", "value": "Gross Agricultural Product ($B)"}
            )
            chart = (
                alt.Chart(data)
                .mark_area(opacity=0.3)
                .encode(
                    x="year:T",
                    y=alt.Y("Gross Agricultural Product ($B):Q", stack=None),
                    color="Region:N",
                )
            )
            st.altair_chart(chart, use_container_width=True)
    except URLError as e:
        st.error(
            """
            **This demo requires internet access.**

            Connection error: %s
        """
            % e.reason
        )

page_names_to_funcs = {
    "ì•ˆë…•í•˜ì„¸ìš”" : intro,
    "ë°˜ê°‘ìŠµë‹ˆë‹¤": Info,
    "ë˜ì™€ì£¼ì„¸ìš”": intro,
    "ê°ì‚¬í•©ë‹ˆë‹¤": intro
}

demo_name = st.sidebar.selectbox("íŠœë§ ì½˜í…ì¸ íŒ€ ë¸”ë¡œê·¸", page_names_to_funcs.keys())
page_names_to_funcs[demo_name]()